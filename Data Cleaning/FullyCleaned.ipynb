{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a542d69",
   "metadata": {},
   "source": [
    "codebook : https://www.cdc.gov/brfss/annual_data/2015/pdf/codebook15_llcp.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef1f98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "brfss = pd.read_csv('2015.csv')\n",
    "\n",
    "clean = brfss.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b825c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_STATE</th>\n",
       "      <th>IMONTH</th>\n",
       "      <th>NUMADULT</th>\n",
       "      <th>CCLGHOUS</th>\n",
       "      <th>GENHLTH</th>\n",
       "      <th>PHYSHLTH</th>\n",
       "      <th>CHECKUP1</th>\n",
       "      <th>BPHIGH4</th>\n",
       "      <th>DIABETE3</th>\n",
       "      <th>HLTHPLN1</th>\n",
       "      <th>...</th>\n",
       "      <th>_DRNKWEK</th>\n",
       "      <th>_RFBING5</th>\n",
       "      <th>_SMOKER3</th>\n",
       "      <th>_INCOMG</th>\n",
       "      <th>_BMI5CAT</th>\n",
       "      <th>_AGE80</th>\n",
       "      <th>_DRDXAR1</th>\n",
       "      <th>_RFHYPE5</th>\n",
       "      <th>_RFHLTH</th>\n",
       "      <th>_PASTRNG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b'02'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.990000e+04</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>b'01'</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.397605e-79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _STATE IMONTH  NUMADULT  CCLGHOUS  GENHLTH  PHYSHLTH  CHECKUP1  BPHIGH4  \\\n",
       "0     1.0  b'01'       3.0       NaN      5.0      15.0       1.0      1.0   \n",
       "1     1.0  b'01'       1.0       NaN      3.0      88.0       4.0      3.0   \n",
       "2     1.0  b'02'       2.0       NaN      4.0      15.0       1.0      3.0   \n",
       "3     1.0  b'01'       3.0       NaN      5.0      30.0       1.0      1.0   \n",
       "4     1.0  b'01'       2.0       NaN      5.0      20.0       1.0      3.0   \n",
       "\n",
       "   DIABETE3  HLTHPLN1  ...      _DRNKWEK  _RFBING5  _SMOKER3  _INCOMG  \\\n",
       "0       3.0       1.0  ...  5.397605e-79       1.0       3.0      2.0   \n",
       "1       3.0       2.0  ...  5.397605e-79       1.0       1.0      1.0   \n",
       "2       3.0       1.0  ...  9.990000e+04       9.0       9.0      9.0   \n",
       "3       3.0       1.0  ...  5.397605e-79       1.0       4.0      5.0   \n",
       "4       3.0       1.0  ...  5.397605e-79       1.0       4.0      9.0   \n",
       "\n",
       "   _BMI5CAT  _AGE80  _DRDXAR1  _RFHYPE5  _RFHLTH  _PASTRNG  \n",
       "0       4.0    63.0       1.0       2.0      2.0       2.0  \n",
       "1       3.0    52.0       2.0       1.0      1.0       2.0  \n",
       "2       2.0    71.0       1.0       1.0      2.0       9.0  \n",
       "3       3.0    63.0       1.0       2.0      2.0       2.0  \n",
       "4       2.0    61.0       1.0       1.0      2.0       2.0  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables = ['_STATE','IMONTH','NUMADULT','CCLGHOUS','GENHLTH','PHYSHLTH','CHECKUP1',\n",
    "             'BPHIGH4','DIABETE3','HLTHPLN1','MEDCOST','TOLDHI2','CVDINFR4','ASTHMA3','CHCSCNCR',\n",
    "           'CHCOCNCR','ADDEPEV2','VETERAN3','DECIDE','DIFFALON','SMOKE100','SEX','MARITAL','EDUCA',\n",
    "             'EMPLOY1','CHILDREN','INCOME2','WEIGHT2','ALCDAY5','FRUIT1',\n",
    "             \"FVBEANS\", \"FVGREEN\", \"FVORANG\", \"VEGETAB1\", \n",
    "             \"EXERANY2\", \"EXEROFT1\", \"STRENGTH\", \"LMTJOIN3\", \"ARTHDIS2\", \n",
    "            \"JOINPAIN\", \"PREDIAB1\", \"CAREGIV1\", \"CRGVLNG1\", \"CRGVHRS1\", \"CIMEMLOS\", \"DRADVISE\",\n",
    "             'SCNTMNY1', 'SCNTMEL1','SCNTWRK1','SXORIENT','TRNSGNDR','EMTSUPRT', 'LSATISFY', \n",
    "             'ADPLEASR', 'ADSLEEP', 'ADENERGY', 'ADEAT1','ADFAIL','ADTHINK','MISTMNT','ADANXEV',\n",
    "            '_LMTSCL1', '_LMTWRK1', '_LMTACT1', '_PASTAE1',\n",
    "             '_PAREC1', '_PA300R2', '_PA150R2', '_PAINDX1', '_PACAT1', 'PA1MIN_', '_TOTINDA', \n",
    "             '_VEG23', '_VEGESUM', '_FRTLT1', '_VEGLT1','_FRUTSUM', '_RFDRHV5', '_DRNKWEK', \n",
    "             '_RFBING5', '_SMOKER3', '_INCOMG', '_BMI5CAT', '_AGE80', '_DRDXAR1', \n",
    "             '_RFHYPE5', '_RFHLTH', '_PASTRNG']\n",
    "\n",
    "\n",
    "data = brfss.loc[:, variables]\n",
    "clean = data.copy()\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5039d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning pages 1-34\n",
    "\n",
    "value_map = {1.0: 'Alabama',2.0: 'Alaska', 4.0: 'Arizona', 5.0: 'Arkansas', 6.0: 'California', 8.0: 'Colorado', \n",
    "             9.0: 'Connecticut', 10.0: 'Delaware', 11.0: 'District of Columbia', 12.0: 'Florida', 13.0: 'Georgia',\n",
    "             15.0: 'Hawaii', 16.0: 'Idaho', 17.0: 'Illinois', 18.0: 'Indiana', 19.0: 'Iowa', 20.0: 'Kansas',\n",
    "             21.0: 'Kentucky',22.0: 'Louisiana',23.0: 'Maine' ,24.0: 'Maryland',25.0: 'Massachusetts',\n",
    "             26.0: 'Michigan' ,27.0: 'Minnesota',28.0: 'Mississippi',29.0: 'Missouri',30.0: 'Montana',\n",
    "             31.0: 'Nebraska' ,32.0: 'Nevada'  ,33.0: 'New Hampshire' ,34.0: 'New Jersey' ,35.0: 'New Mexico',\n",
    "             36.0: 'New York' ,37.0: 'North Carolina' ,38.0: 'North Dakota',39.0: 'Ohio'  ,40.0: 'Oklahoma',\n",
    "             41.0: 'Oregon',42.0: 'Pennsylvania',44.0: 'Rhode Island',45.0: 'South Carolina',46.0: 'South Dakota',\n",
    "             47.0: 'Tennessee',48.0: 'Texas',49.0: 'Utah',50.0: 'Vermont',51.0: 'Virginia',53.0: 'Washington',\n",
    "             54.0: 'West Virginia',55.0: 'Wisconsin',56.0: 'Wyoming',66.0: 'Guam',72.0: 'Puerto Rico'}\n",
    "clean['_STATE'] = clean['_STATE'].replace(value_map)\n",
    "\n",
    "\n",
    "\n",
    "value_map = {b'01': 'January', b'02': 'February', b'03': 'March', b'04': 'April', b'05':'May',b'06':'June',\n",
    "             b'07':'July',b'08':'August',b'09': 'Spetember', b'10':'Ocetober',b'11':'November',b'12':'December'}\n",
    "\n",
    "clean['IMONTH'] = clean['IMONTH'].replace(value_map)\n",
    "\n",
    "clean.loc[(clean.NUMADULT == 'BLANK'),'NUMADULT']= pd.NA\n",
    "\n",
    "value_map = {1.0: 'Yes', 'BLANK':'No'}\n",
    "clean['CCLGHOUS'] = clean['CCLGHOUS'].replace(value_map)\n",
    "\n",
    "value_map = {1.0: 'Excellent', 2.0: 'Very Good', 3.0: 'Good', 4.0: 'Fair', 5.0:'Poor',6.0: pd.NA,\n",
    "             7.0: pd.NA ,8.0: pd.NA}\n",
    "clean['GENHLTH'] = clean['GENHLTH'].replace(value_map)\n",
    "\n",
    "clean.loc[(clean.PHYSHLTH == 77),'PHYSHLTH']= pd.NA\n",
    "clean.loc[(clean.PHYSHLTH == 99),'PHYSHLTH']= pd.NA\n",
    "clean.loc[(clean.PHYSHLTH == 88),'PHYSHLTH']=0\n",
    "\n",
    "value_map = {1.0: 'One year', 2.0: 'Two years', 3.0: 'Five years', 4.0: 'over five', \n",
    "             7.0:pd.NA,8.0:'Never',9.0: pd.NA, 'BLANK':pd.NA}\n",
    "\n",
    "clean['CHECKUP1'] = clean['CHECKUP1'].replace(value_map)\n",
    "\n",
    "\n",
    "value_map = {1.0: 'Yes', 2.0: 'NO', 3.0:'NO', 4.0:'NO',7.0:pd.NA, 9.0: pd.NA, 'BLANK':pd.NA}\n",
    "\n",
    "clean['BPHIGH4'] = clean['BPHIGH4'].replace(value_map)\n",
    "\n",
    "value_map = {1.0: 'Yes', 2.0: 'NO', 3.0:'NO', 4.0:'NO',7.0:pd.NA, 9.0: pd.NA, 'BLANK':pd.NA}\n",
    "\n",
    "clean['DIABETE3'] = clean['DIABETE3'].replace(value_map)\n",
    "\n",
    "var_list = ['HLTHPLN1','MEDCOST','TOLDHI2','CVDINFR4','ASTHMA3','CHCSCNCR',\n",
    "           'CHCOCNCR','ADDEPEV2','VETERAN3','DECIDE','DIFFALON','SMOKE100']\n",
    "\n",
    "for var in var_list:\n",
    "    \n",
    "    value_map = {1.0: 1, 2.0: 0, 7.0:pd.NA, 9.0: pd.NA, 'BLANK':pd.NA}\n",
    "\n",
    "    clean[var] = clean[var].replace(value_map)\n",
    "    \n",
    "\n",
    "value_map = {1.0: 'Male', 2.0: 'Female'}\n",
    "clean['SEX'] = clean['SEX'].replace(value_map)\n",
    "\n",
    "value_map = {1.0: 'Married', 2.0: 'Divorces', 3.0: 'Widowed', 4.0: 'Separated', 5.0:'Never Married',6.0:'Unmarried Couple',\n",
    "             9.0: 'Refused'}\n",
    "\n",
    "clean['MARITAL'] = clean['MARITAL'].replace(value_map)\n",
    "\n",
    "value_map = {1.0: 'None', 2.0: 'primary', 3.0: 'some secondary', 4.0: 'secondary', 5.0:'some college',6.0:'college',\n",
    "             9.0: 'Refused'}\n",
    "\n",
    "clean['EDUCA'] = clean['EDUCA'].replace(value_map)\n",
    "\n",
    "value_map = {1.0: 'Employed', 2.0: 'Self-Employed', 3.0: '1 year out of work', 4.0: 'less than 1 year out of work', 5.0:'homemaker',6.0:'student',\n",
    "             7.0:'retired',8.0:'unable to work',9.0: pd.NA}\n",
    "\n",
    "clean['EMPLOY1'] = clean['EMPLOY1'].replace(value_map)\n",
    "\n",
    "clean.loc[(clean.CHILDREN == 'BLANK'),'CHILDREN']= pd.NA\n",
    "clean.loc[(clean.CHILDREN == 99),'CHILDREN']= pd.NA\n",
    "clean.loc[(clean.CHILDREN == 88),'CHILDREN']=0\n",
    "\n",
    "value_map = {1.0: '<10,000', 2.0: '<15,000', 3.0: '<20,000', 4.0: '<25,000', 5.0:'<35,000',6.0:'<50,000',\n",
    "             7.0:'<75,000',8.0:'75,000+',77.0: pd.NA, 99.0:pd.NA,'BLANK':pd.NA}\n",
    "\n",
    "clean['INCOME2'] = clean['INCOME2'].replace(value_map)\n",
    "\n",
    "clean.loc[(clean.WEIGHT2 == 'BLANK'),'WEIGHT2']= pd.NA\n",
    "clean.loc[(clean.WEIGHT2 == 7777),'WEIGHT2']= pd.NA\n",
    "clean.loc[(clean.WEIGHT2 == 9999),'WEIGHT2']=pd.NA\n",
    "\n",
    "clean['WEIGHT2'] = np.where((clean['WEIGHT2'] >= 9000), \n",
    "                               np.mod(clean['WEIGHT2'], 9000)*2.2, clean['WEIGHT2'])\n",
    "\n",
    "\n",
    "clean.loc[(clean.ALCDAY5 == 'BLANK'),'ALCDAY5']= pd.NA\n",
    "clean.loc[(clean.ALCDAY5 == 777),'ALCDAY5']= pd.NA\n",
    "clean.loc[(clean.ALCDAY5 == 999),'ALCDAY5']=pd.NA\n",
    "clean.loc[(clean.ALCDAY5 == 888),'ALCDAY5']=0\n",
    "\n",
    "#making it all within the last month\n",
    "\n",
    "clean['ALCDAY5'] = np.where((clean['ALCDAY5'] <= 200), \n",
    "                               np.mod(clean['ALCDAY5'], 100)*4, clean['ALCDAY5'])\n",
    "clean['ALCDAY5'] = np.where((clean['ALCDAY5'] >= 200), \n",
    "                               np.mod(clean['ALCDAY5'], 200), clean['ALCDAY5'])\n",
    "\n",
    "\n",
    "clean.loc[(clean.FRUIT1 == 'BLANK'),'FRUIT1']= pd.NA\n",
    "clean.loc[(clean.FRUIT1 == 777),'FRUIT1']= pd.NA\n",
    "clean.loc[(clean.FRUIT1 == 999),'FRUIT1']=pd.NA\n",
    "clean.loc[(clean.FRUIT1 == 555),'FRUIT1']=0\n",
    "clean.loc[(clean.FRUIT1 == 300),'FRUIT1']=0\n",
    "\n",
    "#making it all within the last month\n",
    "clean['FRUIT1'] = np.where((clean['FRUIT1'] <= 200), \n",
    "                               np.mod(clean['FRUIT1'], 100)*30, clean['FRUIT1'])\n",
    "clean['FRUIT1'] = np.where((clean['FRUIT1'] >= 200)&(clean['FRUIT1'] < 300), \n",
    "                               np.mod(clean['FRUIT1'], 200)*4, clean['FRUIT1'])\n",
    "clean['FRUIT1'] = np.where((clean['FRUIT1'] > 300)&(clean['FRUIT1'] < 400), \n",
    "                               np.mod(clean['FRUIT1'], 300), clean['FRUIT1'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dcf425bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pages 35-69\n",
    "\n",
    "#Numeric with 100 daily 200 weekly 300 monthly\n",
    "numlist = [\"FVBEANS\", \"FVGREEN\", \"FVORANG\", \"VEGETAB1\"]\n",
    "for var in numlist:\n",
    "    clean[var] = np.where((data[var] >= 100) & (data[var] <= 199), \n",
    "                               np.mod(data[var], 100)*30, clean[var])\n",
    "    clean[var] = np.where((data[var] >= 200) & (data[var] <= 299), \n",
    "                               np.mod(data[var], 200)*4, clean[var])\n",
    "    clean[var] = np.where((data[var] >= 300) & (data[var] <= 399), \n",
    "                               np.mod(data[var], 300), clean[var])\n",
    "    clean[var] = np.where(data[var] == 555, 0, clean[var])\n",
    "    clean[var] = np.where(data[var] == 777, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 999, np.nan, clean[var])\n",
    "\n",
    "#Numeric but 100+ is weekly 200+ is monthly\n",
    "numlist2 = [\"EXEROFT1\", \"STRENGTH\"]\n",
    "for var in numlist2:\n",
    "    clean[var] = np.where((data[var] >= 100) & (data[var] <= 199), \n",
    "                               np.mod(data[var], 100)*4, clean[var])\n",
    "    clean[var] = np.where((data[var] >= 200) & (data[var] <= 299), \n",
    "                               np.mod(data[var], 200), clean[var])\n",
    "    clean[var] = np.where(data[var] == 777, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 888, 0, clean[var])\n",
    "    clean[var] = np.where(data[var] == 999, np.nan, clean[var])\n",
    "    \n",
    "#Binary vars\n",
    "binarylist = [\"EXERANY2\", \"LMTJOIN3\", \"ARTHDIS2\", \"CIMEMLOS\", \"DRADVISE\"]\n",
    "for var in binarylist:\n",
    "    clean[var] = np.where(data[var] == 2, 0, clean[var])\n",
    "    clean[var] = np.where(data[var] == 7, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 9, np.nan, clean[var])\n",
    "    \n",
    "#1-10 vars\n",
    "list1_10 = [\"JOINPAIN\"]\n",
    "for var in list1_10:\n",
    "    clean[var] = np.where(data[var] == 7, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 9, np.nan, clean[var])\n",
    "    \n",
    "#yes, yes during pregnancy, and no. Convert to binary\n",
    "almost_binarylist = [\"PREDIAB1\"]\n",
    "for var in almost_binarylist:\n",
    "    clean[var] = np.where(data[var] == 2, 1, clean[var])\n",
    "    clean[var] = np.where(data[var] == 3, 0, clean[var])\n",
    "    clean[var] = np.where(data[var] == 7, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 9, np.nan, clean[var])\n",
    "   \n",
    "\n",
    "almost_binarylist2 = [\"CAREGIV1\"]\n",
    "for var in almost_binarylist2:\n",
    "    clean[var] = np.where(data[var] == 7, np.nan, clean[var])\n",
    "    clean[var] = np.where(data[var] == 8, 1, clean[var]) #Died\n",
    "    clean[var] = np.where(data[var] == 9, np.nan, clean[var])\n",
    "    \n",
    "CRGVLNG1_map = {1.0: '<30 days', 2.0: '1-6 months', 3.0: '0.5-2 years', 4.0: '2-5 years', 5.0: '5+ years'}\n",
    "clean[\"CRGVLNG1\"] = clean[\"CRGVLNG1\"].replace(CRGVLNG1_map)\n",
    "clean[\"CRGVLNG1\"] = np.where(data[\"CRGVLNG1\"] == 7, np.nan, clean[\"CRGVLNG1\"])\n",
    "clean[\"CRGVLNG1\"] = np.where(data[\"CRGVLNG1\"] == 9, np.nan, clean[\"CRGVLNG1\"])\n",
    "\n",
    "CRGVHRS1_map = {1.0: '0-8 hours/week', 2.0: '9-19 hours/week', 3.0: '20-39 hours/week', 4.0: '40+ hours/week'}\n",
    "clean[\"CRGVHRS1\"] = clean[\"CRGVHRS1\"].replace(CRGVHRS1_map)\n",
    "clean[\"CRGVHRS1\"] = np.where(data[\"CRGVHRS1\"] == 7, np.nan, clean[\"CRGVHRS1\"])\n",
    "clean[\"CRGVHRS1\"] = np.where(data[\"CRGVHRS1\"] == 9, np.nan, clean[\"CRGVHRS1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48cb1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "#70-104\n",
    "\n",
    "values = {1: 'Always', \n",
    "          2: 'Usually',\n",
    "          3: 'Sometimes',\n",
    "          4: 'Rarely',\n",
    "          5: 'Never',\n",
    "          7: np.nan,\n",
    "          8: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['SCNTMNY1'] = clean['SCNTMNY1'].replace(values)\n",
    "\n",
    "values = {1: 'Always', \n",
    "          2: 'Usually',\n",
    "          3: 'Sometimes',\n",
    "          4: 'Rarely',\n",
    "          5: 'Never',\n",
    "          7: np.nan,\n",
    "          8: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['SCNTMEL1'] = clean['SCNTMEL1'].replace(values)\n",
    "\n",
    "values = {97 : np.nan,\n",
    "          98 : np.nan,\n",
    "          99 : np.nan}\n",
    "\n",
    "clean['SCNTWRK1'] = clean['SCNTWRK1'].replace(values)\n",
    "\n",
    "values = {1: 'Straight', \n",
    "          2: 'Lesbian or gay',\n",
    "          3: 'Bisexual',\n",
    "          4: 'Other',\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['SXORIENT'] = clean['SXORIENT'].replace(values)\n",
    "\n",
    "values = {1: 'Yes, Transgender, male-to-female', \n",
    "          2: 'Yes, Transgender, female to male',\n",
    "          3: 'Yes, Transgender, gender nonconforming',\n",
    "          4: 'No',\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['TRNSGNDR'] = clean['TRNSGNDR'].replace(values)\n",
    "\n",
    "values = {1: 'Always', \n",
    "          2: 'Usually',\n",
    "          3: 'Sometimes',\n",
    "          4: 'Rarely',\n",
    "          5: 'Never',\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['EMTSUPRT'] = clean['EMTSUPRT'].replace(values)\n",
    "\n",
    "values = {1: 'Very satisfied', \n",
    "          2: 'Satisfied',\n",
    "          3: 'Dissatisfied',\n",
    "          4: 'Very dissatisfied',\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['LSATISFY'] = clean['LSATISFY'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADPLEASR'] = clean['ADPLEASR'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADSLEEP'] = clean['ADSLEEP'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADENERGY'] = clean['ADENERGY'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADEAT1'] = clean['ADEAT1'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADFAIL'] = clean['ADFAIL'].replace(values)\n",
    "\n",
    "values = {88: np.nan,\n",
    "          99: np.nan,\n",
    "          77: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADTHINK'] = clean['ADTHINK'].replace(values)\n",
    "\n",
    "values = {1: 1,\n",
    "          2 : 0,\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['MISTMNT'] = clean['MISTMNT'].replace(values)\n",
    "\n",
    "values = {1: 1,\n",
    "          2 : 0,\n",
    "          7: np.nan,\n",
    "          9: np.nan\n",
    "         }\n",
    "\n",
    "clean['ADANXEV'] = clean['ADANXEV'].replace(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b976488",
   "metadata": {},
   "outputs": [],
   "source": [
    "#104-134\n",
    "\n",
    "value_map = {1.0: 'Told have arthritis and have limited usual activities', \n",
    "             2.0: 'Told have arthritis and no limited usual activities', \n",
    "             3.0: 'Not told they have arthritis', \n",
    "             9.0: 'Don ́t know, refused or missing usual activities limited'}\n",
    "\n",
    "clean['_LMTACT1'] = clean['_LMTACT1'].replace(value_map)\n",
    "\n",
    "\n",
    "limited_social = {1.0: 'Told have arthritis and social activities limited a lot', \n",
    "             2.0: 'Told have arthritis and social activities limited a little', \n",
    "             3.0: 'Told have arthritis and social activities not limited',\n",
    "             4.0: 'Not told they have arthritis',\n",
    "             9.0: 'Don ́t know, refused or missing usual activities limited'}\n",
    "\n",
    "clean['_LMTSCL1'] = clean['_LMTSCL1'].replace(limited_social)\n",
    "\n",
    "\n",
    "limited_work = {1.0: 'Told have arthritis and have limited work', \n",
    "             2.0: 'Told have arthritis and no limited work', \n",
    "             3.0: 'Not told they have arthritis', \n",
    "             9.0: 'Don ́t know, refused or missing work limited'}\n",
    "\n",
    "work_out = {1.0: '150+ minutes (or vigorous equivalent minutes) of physical activity', \n",
    "             2.0: '1-149 minutes (or vigorous equivalent minutes) of physical', \n",
    "             3.0: '0 minutes', \n",
    "             9.0: 'Don ́t know, refused or missing work limited'}\n",
    "\n",
    "clean['_PA150R2'] = clean['_PA150R2'].replace(limited_work)\n",
    "\n",
    "\n",
    "clean['_LMTWRK1'] = clean['_LMTWRK1'].replace(limited_work)\n",
    "\n",
    "\n",
    "aerobic_strength = {1.0: 'Met Both Guidelines', \n",
    "             2.0: 'Did Not Meet Both Guidelines', \n",
    "             9.0: 'Don ́t know, refused or missing usual activities limited'}\n",
    "\n",
    "clean['_PASTAE1'] = clean['_PASTAE1'].replace(aerobic_strength)\n",
    "\n",
    "\n",
    "strength_dos = {1.0: 'Met Both Guidelines', \n",
    "             2.0: 'Met Aerobic Guidelines Only',\n",
    "             3.0: ' Met Strenghtening Guidelines Only',\n",
    "             4.0: 'Did not meet Either Guideline',\n",
    "             9.0: 'Don ́t know, refused or missing usual activities limited'}\n",
    "\n",
    "clean['_PAREC1'] = clean['_PAREC1'].replace(strength_dos)\n",
    "\n",
    "\n",
    "phys_act = {1.0: 'Highly Active', \n",
    "             2.0: 'Active', \n",
    "             3.0: 'Insufficiently Active',\n",
    "             4.0: 'Inactive',\n",
    "             9.0: 'Don ́t know, refused or missing'}\n",
    "\n",
    "clean['_PACAT1'] = clean['_PACAT1'].replace(phys_act)\n",
    "\n",
    "binarylist = [\"_PASTRNG\", \"_PAINDX1\", \"_PASTRNG\", \"_TOTINDA\", \"_VEGLT1\", \"_FRTLT1\", \"_RFDRHV5\", \"_RFBING5\", \"_RFHYPE5\", \"_RFHLTH\", \"_DRDXAR1\"]\n",
    "for var in binarylist:\n",
    "    clean[var] = np.where(clean[var] == 2, 0, clean[var])\n",
    "    clean[var] = np.where(clean[var] == 7, np.nan, clean[var])\n",
    "    clean[var] = np.where(clean[var] == 9, np.nan, clean[var])\n",
    "    \n",
    "weight = {1.0: 'under weight',\n",
    "               2.0: 'normal weight',\n",
    "               3.0: 'overweight',\n",
    "               4.0: 'obese'}\n",
    "\n",
    "clean['_BMI5CAT'] = clean['_BMI5CAT'].replace(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a43a71f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07260293211554493"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replacing 88 with 0 because 88 means none (codebook)\n",
    "brfss.loc[(brfss.MENTHLTH == 88),'MENTHLTH']=0\n",
    "\n",
    "# replacing 77 and 99 with NA (codebook)\n",
    "brfss.loc[(brfss.MENTHLTH == 77),'MENTHLTH']= pd.NA\n",
    "brfss.loc[(brfss.MENTHLTH == 99),'MENTHLTH']= pd.NA\n",
    "\n",
    "brfss['MENTHLTH']\n",
    "\n",
    "# finding 2 standard deviations above the mean\n",
    "brfss['MENTHLTH'].mean() + (2*(brfss['MENTHLTH'].std()))\n",
    "\n",
    "# create new column with the people above 2 sd above the mean calssified as poor mental health,\n",
    "# and all others classified as not\n",
    "clean['POOR_MENTHLTH'] = brfss['MENTHLTH']\n",
    "\n",
    "clean.loc[(clean.POOR_MENTHLTH >= 18.0),'POOR_MENTHLTH']=1\n",
    "\n",
    "clean.loc[(clean.POOR_MENTHLTH <= 18.5),'POOR_MENTHLTH']=0\n",
    "\n",
    "clean['POOR_MENTHLTH'].sum()\n",
    "\n",
    "len(clean['POOR_MENTHLTH'])\n",
    "\n",
    "32051/441456"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652f8ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
